% TEMPLATE for Usenix papers, specifically to meet requirements of
%  USENIX '05
% originally a template for producing IEEE-format articles using LaTeX.
%   written by Matthew Ward, CS Department, Worcester Polytechnic Institute.
% adapted by David Beazley for his excellent SWIG paper in Proceedings,
%   Tcl 96
% turned into a smartass generic template by De Clarke, with thanks to
%   both the above pioneers
% use at your own risk.  Complaints to /dev/null.
% make it two column with no page numbering, default is 10 point

% Munged by Fred Douglis <douglis@research.att.com> 10/97 to separate
% the .sty file from the LaTeX source template, so that people can
% more easily include the .sty file into an existing document.  Also
% changed to more closely follow the style guidelines as represented
% by the Word sample file. 

% Note that since 2010, USENIX does not require endnotes. If you want
% foot of page notes, don't include the endnotes package in the 
% usepackage command, below.

% This version uses the latex2e styles, not the very ancient 2.09 stuff.
\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix,epsfig,endnotes}
\begin{document}

%don't want date printed
\date{}

%make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf The Design and Implementation of the Warp Transactional Filesystem}

%for single author (just remove % characters)
\author{
{\rm Sean Ogden}\\
Cornell University
% copy the following lines to add more authors
% \and
% {\rm Name}\\
%Name Institution
} % end author

\maketitle

% Use the following at camera-ready time to suppress page numbers.
% Comment it out when you first submit the paper for review.
\thispagestyle{empty}


\subsection*{Abstract}
We have designed and implemented the Warp Transactional
Filesystem, a distributed filesystem for storing large
data.  It supports atomic file operations, and has
better aggregate throughput and latency, and stronger fault
tolerance properties than existing publically available
distributed file systems.

While previous distributed filesystems have many of the
same features as WTF, they do not provide strong enough
consistency guarantees to implement useful features such
as atomic file append.  Furthermore, existing designs
rely on a single master to store metadata in memory,
resulting in non-uniform hardware requirements, weak fault
tolerance properties, filesystem size limitations, 
and performance bottlenecks.

In this paper we present the transactional API, 
design and implementation details, and performance
evaluation of the Warp Transactional Filesystem.

\section{Introduction}

We have designed and implemented the Warp Transactional Filesystem,
a distributed, fault tolerant, high throughput system
for storing large amounts of data.  WTF's design has been
heavily influenced by existing file systems such as the Google File System
and the closely related but publically available Hadoop File System.
However, WTF's goal of supporting atomic operations, stronger fault
tolerance, and higher performance have caused us to stray significantly
from the norm in some key areas.

First, our file system has been designed specifically to support
atomic, file and file system operations.  As the authors of the
Google File System point out, the most frequently used operation
is by far append.  However, GFS does not support atomically
appending arbitrary bytes on to the end of a file, or changing
multiple files in one atomic action.  Instead, it
supports atomic record append, which exhibits "at least once"
semantics instead of the usual "at most once".  This
means that the Google File System does not guarantee that all
replicas of a file are bytewise identical.  In contrast,
the Warp Transactional File System supports arbitrary atomic
file operations in the traditional sense: at most one semantics
and bytewise identical replicas.

Second, the Warp Transactional File System is not a single
master system.  Traditional distributed file systems have used
single master to ease implementation.  This has resulted in some
unfortunate consequences.  For example, in HDFS and GFS, all block
information must be stored in the memory of the namenode.  This requires
the provisioning of a "special" node which has higher memory resources 
than all others in the system.  Furthermore, since the master is on the
write path, this can lead to perfromance bottlenecks in write heavy
systems.  Instead of a single master, we use a HyperDex Warp cluster 
to hold all file metadata.  HyperDex Warp is a high-performance,
consistent, scalable, distributed key-value store that supports
multi-key ACID transactions and efficient search operations.  
HyperDex Warp uses very little memory per instance
and the entire cluster can be configured to run on the same nodes
as the block storage daemons, eliminating the need for special
high memory instances.

Third, the most popular publically available distributed file system,
HDFS, does not support asynchronous file operations.  The WTF
API is fully asynchronous, resulting in improved throughput
across the board.  We provide synchronous wrapper functions
for ease of use.

Lastly, the publically available distributed file systems
today are typically writen in high level languages such as Java,
and performance has been sacrificed as a result. WTF has been
fully implemented in roughly 10,000 lines of C++ and AMD64 assembly,
resulting in superior performance even in cases where the algorithms
and design are similar.

\section{Related Work}

Caching layers on top of distributed filesystems such as
Spark aim to speed up bulk data processing tasks by 
lazily performing transformations on data and storing the
results in in-memory shards on the storage nodes of a 
distributed file system.  These systems leave the
distributed filesystem relatively unchanged, relying upon
them perform durable writes.  This work is orthogonal
to caching systems, and indeed it would be easy to implement such a
caching system on top of a WTF.

AFS, AFS2 and Coda FS are primarily concerned caching files
locally on client disk to speed up interactive access to
the file system.  When opening a file, the entire file is cached
on client local disk before any reading or writing takes place, implicitly
assuming that files are relatively small.  While they do exhibit some 
of atomicity in the form of last-write-wins
semantics on file close, they rely on file level replication instead
of transactions and can occasionally allow clients to see stale state
when the cache is not updated.  WTF relies on atomic transactions over the metadata
store and can thus use block level replication to allow for very large
files and better load distribution and concurrency.  

Peer-to-Peer based file systems such as CFS and Pond 
hash the contents
of blocks and store them within a distributed hash table.  WTF
uses a key-value store only for storing the file and block
metadata, and therefore has greater flexibility in block placement
strategies which can be beneficial for load balancing data
processing applications that run on top of the file system.

Like WTF, Frangipani and Antiquity also use a distributed master for 
metadata storage.  
Frangipani relies on the storage nodes themselves to implement
a Paxos based algorithm to replicate state across every storage
node.  Antiquity is one step closer to WTF in that its metadata
storage layer is
independent of the block storage servers.  In contrast to  
WTF, Antiquity is designed to be run in an untrusted, unreliable 
environment and relies on the secure hash of existing files
to implement atomic append operations.  WTF assumes a typical 
trusted datacenter environment and implements no security features,
relying on ACID transactions of the metadata store to provide
atomic file system operations. 

The Google File System and HDFS are perhaps the closest systems
to WTF.  Like WTF, both employ relatively dumb storage nodes
that store data in immutable blocks,
achieve fault tolerance by block-level replication, employ large block sizes
to minimize disk seeks, and are designed as storage layers
for non-interactive, high throughput applictions like MapReduce.
Unlike these systems, WTF does not allow files to be in an undefined
state, as each file operation is an ACID transaction.  The implementation
of WTF also differs in that it uses a distributed
key-value store as the master enabling further scalability and higher
throughput while maintaining atomicity of file metadata operations.
The WTF master does not store any client state such
as whether files are open.

\end{document}
